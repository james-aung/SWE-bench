{"repo": "psf/requests", "pull_number": 6644, "instance_id": "psf__requests-6644", "issue_numbers": ["6643"], "base_commit": "382fc2c0c6c0ef0874bc65bc1175f97c073e5086", "patch": "diff --git a/src/requests/adapters.py b/src/requests/adapters.py\nindex eb240fa954..fc5606bdcb 100644\n--- a/src/requests/adapters.py\n+++ b/src/requests/adapters.py\n@@ -390,6 +390,9 @@ def request_url(self, request, proxies):\n             using_socks_proxy = proxy_scheme.startswith(\"socks\")\n \n         url = request.path_url\n+        if url.startswith(\"//\"):  # Don't confuse urllib3\n+            url = f\"/{url.lstrip('/')}\"\n+\n         if is_proxied_http_request and not using_socks_proxy:\n             url = urldefragauth(request.url)\n \n", "test_patch": "diff --git a/tests/test_adapters.py b/tests/test_adapters.py\nnew file mode 100644\nindex 0000000000..6c55d5a130\n--- /dev/null\n+++ b/tests/test_adapters.py\n@@ -0,0 +1,8 @@\n+import requests.adapters\n+\n+\n+def test_request_url_trims_leading_path_separators():\n+    \"\"\"See also https://github.com/psf/requests/issues/6643.\"\"\"\n+    a = requests.adapters.HTTPAdapter()\n+    p = requests.Request(method=\"GET\", url=\"http://127.0.0.1:10000//v:h\").prepare()\n+    assert \"/v:h\" == a.request_url(p, {})\n", "problem_statement": "Leading slash in uri followed by column fails\nLeading slash in uri followed by column fails.\r\n\r\n## Expected Result\r\n\r\n```python\r\nrequests.get('http://127.0.0.1:10000//v:h')\r\n<Response [200]>\r\n```\r\n\r\n## Actual Result\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.11/site-packages/urllib3/util/url.py\", line 425, in parse_url\r\n    host, port = _HOST_PORT_RE.match(host_port).groups()  # type: ignore[union-attr]\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'groups'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/api.py\", line 73, in get\r\n    return request(\"get\", url, params=params, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/api.py\", line 59, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\r\n    r = adapter.send(request, **kwargs)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\r\n    resp = conn.urlopen(\r\n           ^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 711, in urlopen\r\n    parsed_url = parse_url(url)\r\n                 ^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/urllib3/util/url.py\", line 451, in parse_url\r\n    raise LocationParseError(source_url) from e\r\nurllib3.exceptions.LocationParseError: Failed to parse: //v:h\r\n```\r\n\r\n## Reproduction Steps\r\n\r\n```python\r\nimport requests\r\nrequests.get('http://127.0.0.1:10000//v:h')\r\n\r\n```\r\n\r\n## System Information\r\n\r\n    $ python -m requests.help\r\n\r\n```json\r\n{\r\n  \"chardet\": {\r\n    \"version\": null\r\n  },\r\n  \"charset_normalizer\": {\r\n    \"version\": \"3.3.2\"\r\n  },\r\n  \"cryptography\": {\r\n    \"version\": \"\"\r\n  },\r\n  \"idna\": {\r\n    \"version\": \"3.6\"\r\n  },\r\n  \"implementation\": {\r\n    \"name\": \"CPython\",\r\n    \"version\": \"3.11.8\"\r\n  },\r\n  \"platform\": {\r\n    \"release\": \"5.10.209-198.812.amzn2.x86_64\",\r\n    \"system\": \"Linux\"\r\n  },\r\n  \"pyOpenSSL\": {\r\n    \"openssl_version\": \"\",\r\n    \"version\": null\r\n  },\r\n  \"requests\": {\r\n    \"version\": \"2.31.0\"\r\n  },\r\n  \"system_ssl\": {\r\n    \"version\": \"300000b0\"\r\n  },\r\n  \"urllib3\": {\r\n    \"version\": \"2.2.1\"\r\n  },\r\n  \"using_charset_normalizer\": true,\r\n  \"using_pyopenssl\": false\r\n}\r\n```\r\n\r\n<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,\r\nplease provide some basic information about your system (Python version,\r\noperating system, &c). -->\r\n\n", "hints_text": "I can reproduce this with\r\n\r\n```py\r\nimport urllib3\r\n\r\nurllib3.PoolManager().urlopen(method=\"GET\", url=\"http://127.0.0.1:10000//v:h\")\r\n```\r\n\r\ncc @sethmlarson @pquentin \nAh I see the problem, both the PoolManager and requests are sending the path (`//v:h`) to `urlopen`: https://github.com/urllib3/urllib3/blob/d4ffa29ee1862b3d1afe584efb57d489a7659dac/src/urllib3/poolmanager.py#L444 https://github.com/psf/requests/blob/7a13c041dbef42f9f3feb14110f02626f6892e9a/src/requests/adapters.py#L487 and `urlopen` is now probably taking on too many responsibilities: https://github.com/urllib3/urllib3/blob/d4ffa29ee1862b3d1afe584efb57d489a7659dac/src/urllib3/connectionpool.py#L711-L712\nAlso, yes, I verified that RFC3986 allows `:` as a non-percent-encoded character in the path: https://datatracker.ietf.org/doc/html/rfc3986.html#section-3.3\nAnd I think the problem is the `//` in the path which is tripping up the parsing as `//` is the delimiter for what should be host and port after that. So in reality nothing is wrong here. I wonder if we need some kind of pre-parsing of the URL before sending it to `urlopen` to  trim this down. Something like `re.sub('^/+', '/')` would likely fix this in both Requests and urllib3.", "created_at": "2024-02-22T01:11:15Z"}
{"repo": "psf/requests", "pull_number": 6629, "instance_id": "psf__requests-6629", "issue_numbers": ["6628"], "base_commit": "7a13c041dbef42f9f3feb14110f02626f6892e9a", "patch": "diff --git a/src/requests/exceptions.py b/src/requests/exceptions.py\nindex e1cedf883d..83986b4898 100644\n--- a/src/requests/exceptions.py\n+++ b/src/requests/exceptions.py\n@@ -41,6 +41,16 @@ def __init__(self, *args, **kwargs):\n         CompatJSONDecodeError.__init__(self, *args)\n         InvalidJSONError.__init__(self, *self.args, **kwargs)\n \n+    def __reduce__(self):\n+        \"\"\"\n+        The __reduce__ method called when pickling the object must\n+        be the one from the JSONDecodeError (be it json/simplejson)\n+        as it expects all the arguments for instantiation, not just\n+        one like the IOError, and the MRO would by default call the\n+        __reduce__ method from the IOError due to the inheritance order.\n+        \"\"\"\n+        return CompatJSONDecodeError.__reduce__(self)\n+\n \n class HTTPError(RequestException):\n     \"\"\"An HTTP error occurred.\"\"\"\n", "test_patch": "diff --git a/tests/test_requests.py b/tests/test_requests.py\nindex 34796dc7ec..77aac3fecb 100644\n--- a/tests/test_requests.py\n+++ b/tests/test_requests.py\n@@ -2810,3 +2810,13 @@ def test_status_code_425(self):\n         assert r4 == 425\n         assert r5 == 425\n         assert r6 == 425\n+\n+\n+def test_json_decode_errors_are_serializable_deserializable():\n+    json_decode_error = requests.exceptions.JSONDecodeError(\n+        \"Extra data\",\n+        '{\"responseCode\":[\"706\"],\"data\":null}{\"responseCode\":[\"706\"],\"data\":null}',\n+        36,\n+    )\n+    deserialized_error = pickle.loads(pickle.dumps(json_decode_error))\n+    assert repr(json_decode_error) == repr(deserialized_error)\n", "problem_statement": "[BUG] JSONDecodeError can't be deserialized - invalid JSON raises a BrokenProcessPool and crashes the entire process pool\nHi all,\r\n\r\nI've stumbled upon a bug in the `requests` library, and have a proposal for a fix.\r\n\r\nIn short: I have a process pool running tasks in parallel, that are among other things doing queries to third-party APIs. One third-party returns an invalid JSON document as response in case of error.\r\n\r\nHowever, instead of just having a JSONDecodeError as the result of my job, the entire process pool crashes due to a BrokenProcessPool error with the following stack trace:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.11/concurrent/futures/process.py\", line 424, in wait_result_broken_or_wakeup\r\n    result_item = result_reader.recv()\r\n                  ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/multiprocessing/connection.py\", line 251, in recv\r\n    return _ForkingPickler.loads(buf.getbuffer())\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/requests/exceptions.py\", line 41, in __init__\r\n    CompatJSONDecodeError.__init__(self, *args)\r\nTypeError: JSONDecodeError.__init__() missing 2 required positional arguments: 'doc' and 'pos'\r\n```\r\n\r\nSo I'm in a situation where receiving one invalid JSON as response is interrupting all my ongoing tasks because the entire process pool is crashing, and no more tasks can be submitted until the process pool recovered.\r\n\r\n## Origin of the bug + Fix\r\n\r\nAfter investigation, this is because the `requests.exception.JSONDecodeError` instances can't be deserialized once they've been serialized via `pickle`. So when the main process is trying to deserialize the error returned by the child process, the main process is crashing with to the error above.\r\n\r\nI think this bug has been around for a while, I've found old tickets from different projects mentioning issues that are looking similar: https://github.com/celery/celery/issues/5712\r\n\r\nI've pinpointed the bug to the following class: https://github.com/psf/requests/blob/main/src/requests/exceptions.py#L31\r\n\r\nBasically, due the MRO/order of inheritance, the `__reduce__` method used will not be the one of `CompatJSONDecodeError`. Most of the args will therefore be ditched when pickling the instance and it can't be deserialised back because `CompatJSONDecodeError.__init__`  does expect those args. MRO below:\r\n\r\n```\r\nIn [1]: from requests.exceptions import JSONDecodeError\r\n\r\nIn [2]: JSONDecodeError.__mro__\r\nOut[2]:\r\n(requests.exceptions.JSONDecodeError,\r\n requests.exceptions.InvalidJSONError,\r\n requests.exceptions.RequestException,\r\n OSError,\r\n simplejson.errors.JSONDecodeError,\r\n ValueError,\r\n Exception,\r\n BaseException,\r\n object)\r\n```\r\n\r\nI think the fix could be quite simple and should have very little side-effects: to specify a `JSONDecodeError.__reduce__` method that will call the one from the correct parent class (it will be regardless that it is json/simplejson via the Compat class, their respective methods having different signatures).\r\n\r\nI've taken the initiative to write a fix + a test and will raise a pull request to that effect \ud83d\ude4f \r\n\r\n-----\r\n\r\n## Expected Result\r\n\r\nI've written a test for this case: the error can easily be reproduced by simply trying to `pickle.dumps()`  then `pickle.loads()` on a error:\r\n\r\n```python\r\njson_decode_error = requests.exceptions.JSONDecodeError(\r\n    \"Extra data\",\r\n    '{\"responseCode\":[\"706\"],\"data\":null}{\"responseCode\":[\"706\"],\"data\":null}',\r\n    36,\r\n)\r\ndeserialized_error = pickle.loads(pickle.dumps(json_decode_error))\r\nassert repr(json_decode_error) == repr(deserialized_error)\r\n```\r\n\r\nThis assertion should be true\r\n\r\n## Actual Result\r\n\r\nCurrently, instead of passing it'll raise the following error:\r\n\r\n```\r\n>       CompatJSONDecodeError.__init__(self, *args)\r\nE       TypeError: JSONDecodeError.__init__() missing 2 required positional arguments: 'doc' and 'pos'\r\n```\r\n\r\n## Reproduction Steps\r\n\r\nAs mentioned above, this bug is more impactful in a multi-process architecture as it'll break the entire process pool.\r\nFor something looking a bit more like a live-case, I've produced a little snippet with a really simple API returning an invalid JSON: \r\n\r\n```python\r\n# File api.py\r\n\r\nfrom fastapi import FastAPI\r\nfrom starlette.responses import PlainTextResponse\r\n\r\napp = FastAPI()\r\n\r\n\r\n@app.get(\"/\")\r\nasync def root():\r\n    # An invalid json string returned by the endpoint that will trigger a JSONDecodeError when calling `res.json()`\r\n    s = '{\"responseCode\":[\"706\"],\"data\":null}{\"responseCode\":[\"706\"],\"data\":null}'\r\n    return PlainTextResponse(s, media_type=\"application/json\", status_code=400)\r\n\r\n\r\n# Run the API:\r\n# $ uvicorn api:app --reload\r\n#\r\n# curl http://127.0.0.1:8000 will return the invalid json\r\n```\r\n\r\nand the following \r\n\r\n```python\r\nfrom concurrent.futures import ProcessPoolExecutor\r\nfrom concurrent.futures.process import BrokenProcessPool\r\n\r\nimport requests\r\n\r\n\r\ndef my_task():\r\n    response = requests.get('http://127.0.0.1:8000/')\r\n    response.json()\r\n\r\ndef my_main_func():\r\n    with ProcessPoolExecutor(max_workers=4) as executor:\r\n        future = executor.submit(my_task)\r\n        for i in range(0, 5):\r\n            try:\r\n                future.result(timeout=100)\r\n                print(f\"Attempt {i} ok\")\r\n            except BrokenProcessPool:\r\n                print(f\"Attempt {i} - the pool is broken\")\r\n            except requests.JSONDecodeError:\r\n                print(f\"Attempt {i} raises a request JSONDecodeError\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    my_main_func()\r\n```\r\n\r\nInstead of getting the following output:\r\n```\r\nAttempt 0 raises a request JSONDecodeError\r\nAttempt 1 raises a request JSONDecodeError\r\nAttempt 2 raises a request JSONDecodeError\r\nAttempt 3 raises a request JSONDecodeError\r\nAttempt 4 raises a request JSONDecodeError\r\n```\r\n\r\nOne would currently have:\r\n```\r\nAttempt 0 - the pool is broken\r\nAttempt 1 - the pool is broken\r\nAttempt 2 - the pool is broken\r\nAttempt 3 - the pool is broken\r\nAttempt 4 - the pool is broken\r\n```\r\n\r\nAn invalid JSON is crashing the entire process pool and no job can be submitted anymore.\r\n\r\n## System Information\r\n\r\nTested with:\r\n- request==2.31.0\r\n- Python==3.11.7\r\n\r\n-----\r\n\r\nThanks a lot for taking the time to read this long bug report!!\n", "hints_text": "", "created_at": "2024-01-31T16:14:59Z"}
